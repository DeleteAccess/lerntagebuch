---
title: "Tag 1"
date: 2021-09-15
---

Bereits in der ersten Lektion hat mich dieser Kurs überrascht. Ich dachte, wir würden uns mit staubigen Screenshots ins Thema «Bibliotheks- und Archivinformatik» einarbeiten, jedoch wurden wir zugleich mit innovativen Technologien konfrontiert: HedgeDoc (siehe: [GWDG](https://pad.gwdg.de/)), Markdown und GitHub. Das hat definitiv einen guten ersten Eindruck hinterlassen.

Das war dann auch schon das erste Erfolgserlebnis: Mit GitHub und Markdown kenne ich mich bestens aus. Dann könnte ich zumindest in diesen Bereichen Punkte gewinnen. Mit dem eigentlichen Thema «Bibliotheks- und Archivinformatik» habe ich jedoch bisher nur wenig Berührungspunkte gehabt. Meine Wissen stützt sich dabei lediglich um ein, zwei Stunden Theorie zur Archivinformatik durchs Studium der Informationswissenschaft und auf die Erfahrung als Frontend-User von Bibliothekssuchmaschinen.

Von meinem Mitstudenten wurden in der Vorstellungsrunde bereits viele Technologien genannt, die mir noch nichts sagen: ALMA (SLSP), aDIS, KOHA, Aleph, Winmedio, SISIS.Sunrise, GEVER, CMI Axioma, STAR II, Evidence und so weiter. Einzig «SAP» ist mir aus meiner beruflicher Erfahrung ein bekannter Begriff – auch wenn für mich SAP bisher mehr eine Blackbox als etwas anderes war.

Es freute mich jedoch zu sehen, dass in diesem Modul viele der vorhergegangenen Module zusammenkommt. Laut Angaben sind dies: ARIS, IRGR, PROG, WINF, WOR1 und WOR2. So könnte ich mir vorstellen, dass dieses Modul eine Mischung aus informationswissenschaftlichen Theorien und informationstechnologischen Systemen sein wird. Ich würde mich natürlich freuen zu programmieren, nehme aber an, dass es nicht über leichtes «Scripting» hinausgehen wird.

Bezüglich den Lernzielen hat das Thema «Suchmaschinen zu konfigurieren» mein Interesse geweckt. Ich würde selbst gerne mal eine Metasuchmaschine bauen. Deshalb erhoffe ich mir, in diesem Modul mehr fundamentales Wissen über Suchmaschinen anzueignen.

«Crosswalks» sind mir ebenfalls noch nicht ein Begriff gewesen. Laut Wikipedia geht es dabei ums «Metadata Mapping», das Übersetzen von Daten in Systeme mit unterschiedlichen Formaten. Das klingt unglaublich wertvoll und könnte mir in meiner weiteren Karriere als Data Engineer von Nutzen sein.

In den Übungen haben wir uns mit Virtuellen Maschinen und Linux beschäftigt. Da ich beides fast jeden Tag nutze, war dies eine leichte Übung für mich. Ich war also bestens amüsiert, dass in den Übungen die klassischen Linux-Kommandos wie ```cd``` (change directory), ```mv``` (move), ```mkdir``` und ```cp``` (copy) aufgetaucht sind. Ich denke jedoch, dass sie eine gute Wiederholung für meine Mitstudenten waren. Für die meisten von ihnen ist das Thema «Linux» wahrscheinlich eine Weile her. Ich hoffe, dass einige von ihnen in diesem Kurs Gefallen daran finden, das Terminal zu benutzen. Ich bin gespannt, ob wir die Bibliotheks- beziehungsweise Archivsysteme auch mittels Terminal oder Ähnlichem ansprechen werden. Jegliche Art der Automation wäre natürlich willkommen.

Glücklicherweise habe ich in der Übung selbst ebenfalls noch etwas Neues gelernt: Die Kommandos ```head```, ```tail``` und ```less ```. Ich hoffe, wir werden noch mehr Linux- beziehungsweise Unix-Kommandos für die Datenverarbeitung lernen. Nach meiner Erfahrung sind diese oftmals universal, d.h. in vielen anderen Systemen anwendbar. 
