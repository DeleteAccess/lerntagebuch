---
title: "Tag 7"
date: 2021-12-03
---

Heute hat sich gezeigt, dass die Geduld sich ausgezahlt hat, denn der Schwerpunkt lag auf **OpenRefine**:

>  "A free, open source, powerful tool for working with messy data”

Mit OpenRefine können tabellarische Daten geladen und überarbeitet werden. OpenRefine hat [eine vorbildliche Open-Source Community ](https://github.com/OpenRefine/OpenRefine/graphs/contributors) (ganz anders als Marc Edit, wo wir am Abend davor gesehen haben).

Das Tool kann direkt auf dem PC installiert werden. Ebenso gibt es die Möglichkeit, OpenRefine online für andere User anzubieten (das hat und geholfen, denn bei einigen war die VDI langsam und Herr Lohmeier konnte dann kurzerhand einen Server aufsetzen, für diese Personen).

---

Mit dem ```wget``` Befehl konnten wir wieder einmal die Software herunterladen. (``` wget https://github.com/OpenRefine/OpenRefine/releases/download/3.5.0/openrefine-linux-3.5.0.tar.gz```)
    
Mit ``` tar -xzf``` können wir die Datei entpacken. 

Nachdem wir OpenRefine installiert haben, und mittels ```./refine``` (vom entpackten Verzeichnis aus) gestartet haben, konnten wir unter ```http://localhost:3333``` OpenRefine darauf zugreifen. Nach etwa sechs Sekunden war OpenRefine verfügbar.

Praktischerweise können wir Daten auch über URL laden, mit der Option *Web Addresses (URL)*. Für die Übung benutzten wir: https://raw.githubusercontent.com/LibraryCarpentry/lc-open-refine/gh-pages/data/doaj-article-sample.csv. Das Laden dauerte nicht mehr als zwei Sekunden und schon wurden diese als Tabelle dargestellt.

---

Danach schauten wir uns einige wichtige Funktionalitäten von OpenRefine an. 

Wir benutzten die **Text Facet** bei Spalte “Language”. Bei jeder Spalte kann **Facet > Text Facet** gewählt werden. Diese Facette wird dann links anzeigt:

![screenshot Text Facet](../img/screenshot-text-facet.png)

In diesem Fall hatten z.B. den Umstand, dass unsere Daten einerseits ein Tag "English" aber auch ein Tag "EN" haben. Glücklicherweise kann man direkt auf *edit* klicken, und bei allen 107 die entsprechenden Zeilen anpassen lassen.

Es gibt aber auch noch komplexere Regeln, z.B. gingen wir übers Feld “Author* auf **Edit cells > Split multi-valued cells**. In diesem Fall wählten wir als Delimeter ```|```. Dadurch, wenn mehrere Autoren in einer Reihe sind, wird nur der erste mit den anderen Angaben stehen und die restlichen Autoren haben (abgesehen von ihrem Namensfeld) eine leere Reihe.

Soweit ich das verstanden habe, und weil wir die Reihen ja auch wieder korrekt zusammensetzen konnten, wird eine Reihe beim Splitten in ein "multi-row record" verwandelt. Das kann mit **Edit cells > Join multi-valued cells…** wieder behoben werden.

Mit dem **Cluster** Button können wir die Autorennamen *mergen*, d.h. dass die Software ähnliche Namen gruppiert und für alle den gleichen Namen definiert. Dieser Prozess kann iterativ mit dem Button **Merge Selected & Re-Cluster** durchgemacht werden. Mehr dazu in der [OpenRefine Doku](https://docs.openrefine.org/manual/cellediting#cluster-and-edit).

Als wir mit ```value.split(",")[0]``` aus dem “Citation” Feld den ersten Wert (das Journal) als neues Feld in allen Reihen hinzugefügt haben, war ich beeindruckt. Solche Möglichkeiten machen OpenRefine nochmals um einige Gradienten wertvoller für mich (dann überrascht es mich nicht, dass "Data Science" als eine der Anwendungen genannt worden ist bei [OpenRefine 2020 Survey Results: Communities](https://raw.githubusercontent.com/OpenRefine/openrefine.github.com/master/images/2020survey/1.png)).

---

Zum Anschluss haben wir uns angeschaut, wie man eine CSV Datei mittels OpenRefine ins MARCXML Format überträgt.


Im **Row Template** sind einige Funktionen mit der Template-Sprache **GREL** gegeben:

* Mit ```value.replace('https://doaj.org/article/','')``` ausser dem Identifier (MARC 001) wird die URL gelöscht
* Mit ```value.escape('xml')``` werden Sonderszeichen ins entsprechende XML-Zeichen übersetzt (z.B. {{"&".escape('xml)}} macht das ```&``` Zeichen zu ```&amp;```) 
* Mit ```['Authors'].value.split('|').slice(1)``` werden die Autoren aufgeteilt (wie oben) und alles vor dem zweiten Wert (```slice(1)```) wird vom Datensatz weggenommen

* "Für die Validierung können Sie das Programm `xmllint` verwenden, das unter Ubuntu vorinstalliert ist."
* "Zum Abgleich gegen das offizielle Schema von MARC21 laden wir dieses (XSD) zunächst herunter."

Mit ```xmllint``` können wir die zuvor mit dem Template exportiertes XML File prüfen:

```shell
xmllint doaj-article-sample-csv.xml --noout --schema MARC21slim.xsd
```

Die Antwort ```doaj-article-sample-csv.xml validates``` bedeutet, dass alles okay ist.
