---
title: "Tag 8"
date: 2021-12-17
---

Zuerst gab es einen Nachtrag zu **XSLT**. 

- XPath ist die Abfrage für XSLT oder so. Finde ich spannend, weil ich XPath von meinem früheren Job kenne, wo wir sie jeweils mit den IDs von HTML-Elementen verglichen haben. Unsere Cloud Plattform hatte dort sozusagen auf einigen Seiten eine komplexere Software embedded. Diese verwendete, wie gesagt, XPath, was die Automation von Test (Test Automation) schwieriger und fehleranfälliger machte.

> ### Zur Motivation  
> 
> Metadaten-Management in der Praxis, hier beim Leibniz-Informationszentrum Wirtschaft (ZBW) in Hamburg:
> * Infoseite: <https://www.zbw.eu/de/ueber-uns/arbeitsschwerpunkte/metadaten/>
> * Videointerview mit Kirsten Jeude: <https://www.youtube.com/watch?v=YwbRTDvt_sA>

Zunächst haben wir erfahren, dass bei **OpenRefine** der Schwerpunkt auf der Datenanreicherung (Reconciliation) liegt. Es wurden auch Alternativen genannt, welche ich hier gerne auflisten möchte:

* [Catmandu](https://librecat.org) (Perl) für Datentransformation
* [Metafacture](https://github.com/metafacture/metafacture-core) (Java) - kann auch als Bestand eines Java Programmes genutzt werden!
* [MarcEdit](https://marcedit.reeset.net) (für MARC21)

Herr Lohmeier hat auch noch erwähnt, wie wichtig es ist, das richtige Tool für die richtige Aufgabe zu nehmen. Dazu ein Beitrag: [Fünf Dinge, die wir mit OpenRefine nicht (gerne) machen](https://fdmlab.landesarchiv-bw.de/post/2021-09-fuenf-dinge-die-wir-mit-openrefine-nicht-machen/).

Wie bereits bekannt, dient JSON als zeitgemässe Alternative zu XML. JSON Lines liefert Datensätze zeilenweise, [was z.B. für die Autovervollständigung genutzt werden kann](https://lobid.org/gnd/api#buld_downloads).

Ein weiteres Tool, welches wirklich cool ist, ist [scrapir](https://scrapir.org/). Dort findet man Daten diverser API von bekannten Webseiten wie Reddit, GitHub und auch seitens der NASA, um nur einige zu nennen. Dort ist klar ersichtlich, dass JSON APIs normalerweise nicht normiert sind.

> ### Hauptthema: Suchmaschinen und Discovery-Systeme
>
> * Solr ist zusammen mit Elasticsearch quasi "Industriestandard".
> ### Suchindex (Solr) oder Datenbank (MySQL)?

| Solr                     | MySQL                   |
| ------------------------ | ----------------------- |
| flache Dokumente         | relationale Datensätze  |
| lexikalische Suche       | reiner Glyphenvergleich |
| keine Konsistenzprüfung  | Transaktionssicherheit  |
| statische Daten          | veränderliche Daten     |
| -> **Retrieval** (Suche) | -> **Storage** (CRUD)   |

> * [CRUD](https://de.wikipedia.org/wiki/CRUD): **C**reate, **R**ead, **U**pdate, **D**elete

***Übung 1: Suche in VuFind vs. Suche in Solr***
Was besonders spannend war, ist dass Solar für die Hits ein Relevanz-Rating berechnet (z.B. je nachdem, ob der Begriff im Titel oder bloss im Abstract vorkommt).

Die zweite Übung war auch interessant, weil sie gezeigt hat, was bei der Tranformation MARC21 ins VuFind-Format falsch gehen kann - so wurde die ID (001 - Control Number bei MARC21) nicht erkannt bzw. hat es nicht funktioniert, weil kein ```controlfield``` mit dem ```tag``` **001** vorhanden war.

![Schaubild zu Lehrinhalten](https://github.com/lhaeller/lerntagebuch/raw/master/img/schaubild-lehrinhalte.png)

*Grafik aus dem gemeinsamen Dokument ([Original](https://github.com/felixlohmeier/bibliotheks-und-archivinformatik/raw/master/images/schaubild-lehrinhalte.png))*

Wird sind nun tatsächlich am Ende dieser Grafik angekommen. Durch den Kurs ist jedes dieses Elemente ein Begriff. Wirklich super.

**TODO: Ganzen Prozess beschreiben.**
