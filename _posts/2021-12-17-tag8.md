---
title: "Tag 8"
date: 2021-12-17
---

Zuerst gab es einen Nachtrag zu **XSLT**. Wenn ich das richtig verstanden habe, ist XPath eine die Abfrage für XSLT. Spannend, weil ich XPath von meinem früheren Job kenne, wo wir sie jeweils mit den IDs von HTML-Elementen verglichen haben. Unsere Cloud Plattform hatte dort sozusagen auf einigen Seiten eine komplexere Software _embedded_. Diese verwendete, wie gesagt, XPath, was die Automation von Test (Test Automation) schwieriger und fehleranfälliger machte.

Zunächst haben wir erfahren, dass bei **OpenRefine** der Schwerpunkt auf der Datenanreicherung (Reconciliation) liegt. Es wurden auch Alternativen genannt, welche ich hier gerne auflisten möchte:

* [Catmandu](https://librecat.org) (Perl) für Datentransformation
* [Metafacture](https://github.com/metafacture/metafacture-core) (Java) - kann auch als Bestand eines Java Programmes genutzt werden!
* [MarcEdit](https://marcedit.reeset.net) (für MARC21)

Herr Lohmeier hat auch noch erwähnt, wie wichtig es ist, das richtige Tool für die richtige Aufgabe zu nehmen. Dazu ein Beitrag: [Fünf Dinge, die wir mit OpenRefine nicht (gerne) machen](https://fdmlab.landesarchiv-bw.de/post/2021-09-fuenf-dinge-die-wir-mit-openrefine-nicht-machen/).

Wie bereits bekannt, dient JSON als zeitgemässe Alternative zu XML. JSON Lines liefert Datensätze zeilenweise, [was z.B. für die Autovervollständigung genutzt werden kann](https://lobid.org/gnd/api#buld_downloads).

Ein weiteres Tool, welches wirklich cool ist, ist [scrapir](https://scrapir.org/). Dort findet man Daten diverser API von bekannten Webseiten wie Reddit, GitHub und auch seitens der NASA, um nur einige zu nennen. Dort ist klar ersichtlich, dass JSON APIs normalerweise nicht normiert sind.

Als Hauptthema haben wir uns _Suchmaschinen und Discovery-Systemen_ gewidmet. Wichtig dabei zu erwähnen ist, dass _Solr_ und _Elasticsearch_ als Industriestandard gelten.

Der aus meiner Sicht wertvollste Teil dieser Vorlesung war die Unterscheidung von einem Suchindex wie _Solr_ und einer Datenbank wie bspw. _MySQL_. An dieser Stelle möchte ich die Tabelle einfügen, welche wir im Unterricht dazu erhalten haben:

| Solr                     | MySQL                   |
| ------------------------ | ----------------------- |
| flache Dokumente         | relationale Datensätze  |
| lexikalische Suche       | reiner Glyphenvergleich |
| keine Konsistenzprüfung  | Transaktionssicherheit  |
| statische Daten          | veränderliche Daten     |
| -> **Retrieval** (Suche) | -> **Storage** (CRUD)   |

**Hinweis:** [CRUD](https://de.wikipedia.org/wiki/CRUD) bedeutet: **C**reate, **R**ead, **U**pdate, **D**elete

Bei der Übung 1: «Suche in VuFind vs. Suche in Solr» war besonders spannend, dass Solar für die Hits ein Relevanz-Rating berechnet (z.B. je nachdem, ob der Begriff im Titel oder bloss im Abstract vorkommt).

Die zweite Übung war auch interessant, weil sie gezeigt hat, was bei der Tranformation MARC21 ins VuFind-Format falsch gehen kann - so wurde die ID (001 - Control Number bei MARC21) nicht erkannt bzw. hat es nicht funktioniert, weil kein ```controlfield``` mit dem ```tag``` **001** vorhanden war.

![Schaubild zu Lehrinhalten](https://github.com/lhaeller/lerntagebuch/raw/master/img/schaubild-lehrinhalte.png)

*Grafik aus dem gemeinsamen Dokument ([Original](https://github.com/felixlohmeier/bibliotheks-und-archivinformatik/raw/master/images/schaubild-lehrinhalte.png))*

Wird sind nun tatsächlich am Ende dieser Grafik angekommen. Durch den Kurs ist jedes dieses Elemente ein Begriff. Wirklich super.
