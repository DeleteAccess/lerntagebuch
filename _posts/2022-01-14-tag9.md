---
title: "Tag 9"
date: 2022-01-14
---

## Rückmeldung zum Lerntagebuch

Eingehend hat Herrn Meyer erklärt, dass _Solr_ schneller als _VuFind_ ist, weil VuFind jeweils zuerst Solr eine Abfrage sendet und dann diese Ergebnisse noch aufbereitet. Danach gab es einen Beitrag über den Unterschied von "horizontalen" und "vertikalen" Suchmaschinen, den ich hier wegen seinem offensichtlichen Nutzen einbinden möchte:


* **Horizontal: unspezifische Suche über heterogene Datenbestände**
    * erfordert kein Datenschema ("schema-less")
    * erlaubt keine semantischen Abfragen oder Feldsuchen
    * Beispiele: Internetsuche, Volltextsuche
* **Vertikal: datenmodell-orientierte Suche über homogene Datenbestände**
    * erfordert ein Datenschema
    * erfordert häufig Datenprozessierung zur Homogenisierung
    * Beispiele: Bibliothekskatalog, Online-Shop


Interessanterweise kann Apache Solr, obwohl es für die vertikale Suche ausgelegt ist, für beides eingesetzt werden. Eine der meistbekannten Alternativen für horizontale Suche ist [Elasticsearch](https://www.elastic.co/de/elasticsearch/) (open-source).

Im nächsten Teil ging es um **Discovery Systeme**, wobei wir gelernt haben, dass _swisscollections_ welches einen Fokus auf digitale Angebot legt, VuFind benutzt.
* swisscollections nutzt VuFind
* swisscollections für Digitale Angebote

* https://www.folio.org/ und VuFind 

## Beispiel zur Harvesting und Transformation für noah.nrw Portal

- github actions läuft auf Azure
- git-scraping: https://simonwillison.net/2020/Oct/9/git-scraping/ -> Historie mittels Git um Veränderung der Daten zu loggen

## Linked Data _ahhand von BIBFRAME und RiC_

Linked Data := "einzelne Infromationsschnitzel für sich zu beschreiben und dann zueinander in Beziehung zu setzen" anstatt einen Datensatz, der alles enthält.

**BIBRAME**

> * basiert auf *Functional Requirements for Bibliographic Records* (FRBR) sowie *Resource Description and Access* (RDA) als Regelwerk, setzt diese aber nicht vollständig um
> * folgt Linked Data Paradigmen

BIBFRAME hat:

* Model := was kann beschrieben werden?
* Vocabulary := wie es beschrieben wird.

Datenmodell bei BIBFRAME = 

* Work = Goethes Faust
* Instance = Versionen / Auflagen
* Item = konkrete Exemplare

Mittels Vokabular beschreibt man Eigenschaften (_engl. properties_):

- Werk hat z.B. _subject, agent_ und _event_
- Instanz hat z.B. _format_, _publisher_
- Item hat z.B. _held by_, _barcode_

BIBRAME Vokabular definiert eine Ontologie := Gesamtheit aller Klassen und ihren Eigenschaften

**Records in Context (RiC)**

> * basiert auf Linked-Data-Prinzipien
> * soll neue und mehrfache Beziehungen zwischen Entitäten ermöglichen

"RiC-O (Records in Contexts-Ontology) is an OWL ontology for describing archival record resources."

![RiC-CM-overview](https://raw.githubusercontent.com/ICA-EGAD/RiC-O/master/diagrams/diagrams_v0-2/RiC-CM-overview/diagram_RiC-CM-overview-RiC-v0-2.jpg)

_"shows the main RiC-CM v0.2 entities and a few relations between them"_, Quelle: https://www.ica.org/standards/RiC/RiC-O_v0-2.html

---

> ## Suchanfragen mit SPARQL am Beispiel des Wikidata Query Service
>
> * Handout zum Query Service: <https://www.wikidata.org/wiki/File:Wikidata_Query_Service_kurzgefasst.pdf>
> * Query-Service: <https://query.wikidata.org> (dort integrierte Beispiele)
> * Weitere Beispiele: <https://blog.wikimedia.de/2016/10/30/10-coole-wikidata-abfragen-die-dir-neue-horizonte-eroeffnen-nummer-7-wird-dich-schockieren/>


> ## Empfehlenswerte Tutorials zum Selbstlernen
> 
> * Library Carpentry: <https://librarycarpentry.org/lessons/>
> * Programming Historian: <https://programminghistorian.org/en/lessons/>
> * openHPI: <https://open.hpi.de/courses>
> * Datenschule: <https://datenschule.de/lernmaterialien/>
